    def __getitem__(self, idx):
        img_path, csv_path = self.samples[idx]

        img = Image.open(img_path).convert("RGB")
        original_width, original_height = img.size

        face = mtcnn(img)
        if face is None:
            face = img
        else:
            face = Image.fromarray(face.permute(1, 2, 0).int().numpy().astype(np.uint8))

        if self.transform:
            face = self.transform(face)

        landmarks = self.load_landmarks(csv_path)

        target_width, target_height = self.target_size
        scale_x = target_width / original_height
        scale_y = target_height / original_height
        landmarks[:, 0] = landmarks[:, 0] * scale_x
        landmarks[:, 1] = landmarks[:, 1] * scale_y
        landmarks = torch.tensor(landmarks.flatten(), dtype=torch.float32)

        return face, landmarks

        def predict_landmarks(img_path, target_size=(224, 224)):
    img = Image.open(img_path).convert("RGB")
    target_width, target_height = target_size

    boxes, _ = mtcnn.detect(img)

    if boxes is None or len(boxes) == 0:
        raise ValueError("No face detected")

    box = boxes[0]
    x1, y1, x2, y2 = box.astype(int)
    face_width = x2 - x1
    face_height = y2 - y1

    face_tensor = mtcnn(img)
    if face_tensor is None:
        raise ValueError("Face detection failed during cropping.")

    face_img = Image.fromarray(
        face_tensor.permute(1, 2, 0).int().numpy().astype(np.uint8)
    )
    face_input = transform(face_img).unsqueeze(0).to(device)

    network.eval()
    with torch.no_grad():
        pred_scaled = network(face_input).cpu().numpy().reshape(-1, 2)

    scale_x = target_width / face_width
    scale_y = target_height / face_height

    pred_unscaled = pred_scaled.astype(float)
    pred_unscaled[:, 0] /= scale_x
    pred_unscaled[:, 1] /= scale_y

    pred_original = pred_unscaled
    pred_original[:, 0] += x1
    pred_original[:, 1] += y1

    return pred_original